{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neurogenesis Demo\n",
    "Train an autoencoder on a small MNIST subset and generate intrinsic replay samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import MLFlowLogger\n",
    "\n",
    "from data.mnist_datamodule import MNISTDataModule\n",
    "from models.autoencoder import AutoEncoder\n",
    "from training.intrinsic_replay_runner import run_intrinsic_replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datamodule restricted to digits 0 and 1\n",
    "dm = MNISTDataModule(batch_size=64, num_workers=0, classes=[0, 1])\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightningModule wrapping the AutoEncoder\n",
    "class LitWrapper(pl.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.ae = model\n",
    "        self.loss_fn = torch.nn.MSELoss()\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.ae(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        imgs, _ = batch\n",
    "        out = self(imgs)\n",
    "        loss = self.loss_fn(out['recon'], imgs.view(imgs.size(0), -1))\n",
    "        self.train_losses.append(loss.item())\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        imgs, _ = batch\n",
    "        out = self(imgs)\n",
    "        self._last_imgs = imgs\n",
    "        self._last_recons = out['recon'].view_as(imgs)\n",
    "        loss = self.loss_fn(out['recon'], imgs.view(imgs.size(0), -1))\n",
    "        self.val_losses.append(loss.item())\n",
    "        self.log('val_loss', loss)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        grid = torchvision.utils.make_grid(\n",
    "            torch.cat([self._last_imgs, self._last_recons], dim=0),\n",
    "            nrow=self._last_imgs.size(0),\n",
    "        )\n",
    "        self.example_grid = grid\n",
    "        self._last_imgs = None\n",
    "        self._last_recons = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder(input_dim=28*28, hidden_sizes=[64, 32], activation='relu')\n",
    "lit = LitWrapper(model)\n",
    "logger = MLFlowLogger(experiment_name='demo')\n",
    "trainer = pl.Trainer(max_epochs=1, logger=logger)\n",
    "trainer.fit(lit, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train losses:', lit.train_losses)\n",
    "print('Val losses:', lit.val_losses)\n",
    "display(torchvision.transforms.ToPILImage()(lit.example_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_intrinsic_replay(\n",
    "    encoder=model.encoder,\n",
    "    decoder=model.decoder,\n",
    "    dataloader=dm.train_dataloader(),\n",
    "    mlf_logger=logger,\n",
    "    n_samples_per_class=16,\n",
    "    device=trainer.strategy.root_device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the intrinsic replay images logged for class 0 and 1\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "artifacts = Path(logger.experiment.get_run(logger.run_id).info.artifact_uri)\n",
    "for cls in [0, 1]:\n",
    "    img = plt.imread(artifacts / f'ir_replay/class_{cls}/ir_class_{cls}.png')\n",
    "    plt.figure();\n",
    "    plt.imshow(img);\n",
    "    plt.axis('off');\n",
    "    plt.title(f'IR samples for class {cls}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
